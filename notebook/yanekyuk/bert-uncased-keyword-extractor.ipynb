{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:cl-tohoku/bert-large-japanese-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Keyword arguments {'is_decoder': True} not recognized.\n",
      "/home/hayato/.cache/pypoetry/virtualenvs/llm-testplay-oBgUYf3M-py3.10/lib/python3.10/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 512, but `max_length` is set to 512. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:私は、粘り強く取り組むことで、目標を達成することに強いこだわりがあります。 長く塾講師のアルバイトをしており、生徒のテストの平均点をあげることが自分のミッションでした。苦手な科目はスタートのエンジンがかかりにくいため、なるべく褒め、楽しい授業をしていくことを心がけました。そして、苦手意識を克服するためには、成功体験を積み重ねることが大事だと考え、自分の生徒にはミニテストなどを頻繁におこない、点数が上がっていくことを短期間で体験してもらうことにしました。 その結果、時間はかかりましたが、全体の平均点を30点上げることに成功しました。私はこの強みを活かし、御社に入社後も粘り強く目標達成に向けて努力したいと考えています。output:粘り強く取り組む//  input:私の強みは臨機応変な対応ができるところです。 ホテルのフロントでアルバイトをしていたのですが、ビジネスマンからお年寄りのご夫婦、家族連れなど幅広いお客様のニーズに寄り添った対応を心掛けてきました。 お年寄りのお荷物をお部屋まで運ぶ、お子様がいらしたときは小さな枕を探してお渡しするなど、マニュアルには載っていない、お客様のご要望に合ったサービスを自分からお声がけしておこないました。 お客様から「ありがとう」と言われる機会も増え、臨機応変な対応こそ、ホスピタリティで重要であることを肌で感じました。 御社に入社したあとは、この臨機応変に対応する力を生かし、お客様に寄り添った対応をしていきたいと考えています。output:臨機応変な対応//  input:私の強みは、計画性があり、優先順位をつけて効率的に取り組めることです。 大学では学内イベント企画の代表を勤め、企画してから実行までの半年間、メンバーの適正を考慮したうえで仕事を振り分け、計画的に準備を進めました。その結果、イベントも大盛況のうちに終えることができました。この成功体験を通じ、計画的に進めることの大切さを改めて感じています。 御社へ入社後も、業務を計画的に効率よく進め、大きな目標を達成していきたいと考えています。output:計画性,優先順位をつけて効率的に取り組める”  input:私は、物事の原因を分析し、適切な対応をすることで問題解決をすることができます。家庭教師のアルバイトをしていたのですが、担当した生徒は英語と歴史が苦手で点数が伸び悩んでいました。そこで、何が苦手であるかを徹底的に分析し、英語は文法が、歴史は時系列が曖昧であることがわかり、それに向けた対策方法として苦手を克服するパズルゲームのように教えるようにしました。その方法が合っていたのか、生徒はみるみる実力をつけ、今では英語と歴史は平均点以上をマークしています。御社へ入社後も、問題解決に向けた原因分析を徹底し、相手の会社が抱えている課題を解決できるよう提案できる営業を目指します。output:適切な対応をすることで問題解決をする”  input:私の強みはプレゼンテーション力があることです。アパレルショップでアルバイトをしていた際、お客様が迷っていたら、コーディネートのアドバイスなどをして売り上げを伸ばしていました。しかし、先輩から「売り上げに意識がいくあまり、アドバイスが的確でない」という指摘を受け、お客様のニーズをしっかり聞き出し、よりお客様のライフスタイルやトレンドに合った提案をするようにしました。その結果、特に売り上げを意識しなくても、自然に売り上げがついてきたのです。御社に入社後も、相手のニーズをしっかりと聞いたうえで適切な提案ができるよう努力したいと考えています。output:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from colorama import Fore, Back, Style, init\n",
    "# need fugashi, unidic_lite\n",
    "init(autoreset=True)\n",
    "\n",
    "# model_name = \"cl-tohoku/bert-base-japanese-v3\"\n",
    "# model_name = \"cl-tohoku/bert-base-japanese-char-v3\"\n",
    "# model_name = \"cl-tohoku/bert-large-japanese-char-v2\"\n",
    "model_name = \"cl-tohoku/bert-large-japanese-v2\"\n",
    "\n",
    "print (\"model:\" + model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# prompt = \"AIによって私達の暮らしは、\"\n",
    "prompt = \"input:私は、粘り強く取り組むことで、目標を達成することに強いこだわりがあります。 長く塾講師のアルバイトをしており、生徒のテストの平均点をあげることが自分のミッションでした。苦手な科目はスタートのエンジンがかかりにくいため、なるべく褒め、楽しい授業をしていくことを心がけました。そして、苦手意識を克服するためには、成功体験を積み重ねることが大事だと考え、自分の生徒にはミニテストなどを頻繁におこない、点数が上がっていくことを短期間で体験してもらうことにしました。 その結果、時間はかかりましたが、全体の平均点を30点上げることに成功しました。私はこの強みを活かし、御社に入社後も粘り強く目標達成に向けて努力したいと考えています。output:粘り強く取り組む//  input:私の強みは臨機応変な対応ができるところです。 ホテルのフロントでアルバイトをしていたのですが、ビジネスマンからお年寄りのご夫婦、家族連れなど幅広いお客様のニーズに寄り添った対応を心掛けてきました。 お年寄りのお荷物をお部屋まで運ぶ、お子様がいらしたときは小さな枕を探してお渡しするなど、マニュアルには載っていない、お客様のご要望に合ったサービスを自分からお声がけしておこないました。 お客様から「ありがとう」と言われる機会も増え、臨機応変な対応こそ、ホスピタリティで重要であることを肌で感じました。 御社に入社したあとは、この臨機応変に対応する力を生かし、お客様に寄り添った対応をしていきたいと考えています。output:臨機応変な対応//  input:私の強みは、計画性があり、優先順位をつけて効率的に取り組めることです。 大学では学内イベント企画の代表を勤め、企画してから実行までの半年間、メンバーの適正を考慮したうえで仕事を振り分け、計画的に準備を進めました。その結果、イベントも大盛況のうちに終えることができました。この成功体験を通じ、計画的に進めることの大切さを改めて感じています。 御社へ入社後も、業務を計画的に効率よく進め、大きな目標を達成していきたいと考えています。output:計画性,優先順位をつけて効率的に取り組める”  input:私は、物事の原因を分析し、適切な対応をすることで問題解決をすることができます。家庭教師のアルバイトをしていたのですが、担当した生徒は英語と歴史が苦手で点数が伸び悩んでいました。そこで、何が苦手であるかを徹底的に分析し、英語は文法が、歴史は時系列が曖昧であることがわかり、それに向けた対策方法として苦手を克服するパズルゲームのように教えるようにしました。その方法が合っていたのか、生徒はみるみる実力をつけ、今では英語と歴史は平均点以上をマークしています。御社へ入社後も、問題解決に向けた原因分析を徹底し、相手の会社が抱えている課題を解決できるよう提案できる営業を目指します。output:適切な対応をすることで問題解決をする”  input:私の強みはプレゼンテーション力があることです。アパレルショップでアルバイトをしていた際、お客様が迷っていたら、コーディネートのアドバイスなどをして売り上げを伸ばしていました。しかし、先輩から「売り上げに意識がいくあまり、アドバイスが的確でない」という指摘を受け、お客様のニーズをしっかり聞き出し、よりお客様のライフスタイルやトレンドに合った提案をするようにしました。その結果、特に売り上げを意識しなくても、自然に売り上げがついてきたのです。御社に入社後も、相手のニーズをしっかりと聞いたうえで適切な提案ができるよう努力したいと考えています。output:\"\n",
    "# prompt = \"吾輩は猫で\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, is_decoder=True).to(model.device)\n",
    "with torch.no_grad():\n",
    "    tokens = model.generate(\n",
    "        **inputs,\n",
    "        max_length=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "    \n",
    "output = tokenizer.decode(tokens[0], skip_special_tokens=True).replace(\" \", \"\")\n",
    "print(f\"{Fore.YELLOW}{prompt}{Fore.WHITE}{output[len(prompt):]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:cl-tohoku/bert-large-japanese-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from colorama import Fore, Back, Style, init\n",
    "\n",
    "# ライブラリの初期化\n",
    "init(autoreset=True)\n",
    "\n",
    "# モデル名を指定\n",
    "model_name = \"cl-tohoku/bert-large-japanese-v2\"\n",
    "\n",
    "print(\"model:\" + model_name)\n",
    "\n",
    "# モデルとトークナイザーを初期化\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"input:私の強みは臨機応変な対応ができるところです。 ホテルのフロントでアルバイトをしていたのですが、ビジネスマンからお年寄りのご夫婦、家族連れなど幅広いお客様のニーズに寄り添った対応を心掛けてきました。 お年寄りのお荷物をお部屋まで運ぶ、お子様がいらしたときは小さな枕を探してお渡しするなど、マニュアルには載っていない、お客様のご要望に合ったサービスを自分からお声がけしておこないました。 お客様から「ありがとう」と言われる機会も増え、臨機応変な対応こそ、ホスピタリティで重要であることを肌で感じました。 御社に入社したあとは、この臨機応変に対応する力を生かし、お客様に寄り添った対応をしていきたいと考えています。output:臨機応変な対応//  input:私の強みは、計画性があり、優先順位をつけて効率的に取り組めることです。 大学では学内イベント企画の代表を勤め、企画してから実行までの半年間、メンバーの適正を考慮したうえで仕事を振り分け、計画的に準備を進めました。その結果、イベントも大盛況のうちに終えることができました。この成功体験を通じ、計画的に進めることの大切さを改めて感じています。 御社へ入社後も、業務を計画的に効率よく進め、大きな目標を達成していきたいと考えています。output:計画性,優先順位をつけて効率的に取り組める”  input:私は、物事の原因を分析し、適切な対応をすることで問題解決をすることができます。家庭教師のアルバイトをしていたのですが、担当した生徒は英語と歴史が苦手で点数が伸び悩んでいました。そこで、何が苦手であるかを徹底的に分析し、英語は文法が、歴史は時系列が曖昧であることがわかり、それに向けた対策方法として苦手を克服するパズルゲームのように教えるようにしました。その方法が合っていたのか、生徒はみるみる実力をつけ、今では英語と歴史は平均点以上をマークしています。御社へ入社後も、問題解決に向けた原因分析を徹底し、相手の会社が抱えている課題を解決できるよう提案できる営業を目指します。output:適切な対応をすることで問題解決をする”  input:私の強みはプレゼンテーション力があることです。アパレルショップでアルバイトをしていた際、お客様が迷っていたら、コーディネートのアドバイスなどをして売り上げを伸ばしていました。しかし、先輩から「売り上げに意識がいくあまり、アドバイスが的確でない」という指摘を受け、お客様のニーズをしっかり聞き出し、よりお客様のライフスタイルやトレンドに合った提案をするようにしました。その結果、特に売り上げを意識しなくても、自然に売り上げがついてきたのです。御社に入社後も、相手のニーズをしっかりと聞いたうえで適切な提案ができるよう努力したいと考えています。output:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'is_decoder': True} not recognized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:私の強みは臨機応変な対応ができるところです。 ホテルのフロントでアルバイトをしていたのですが、ビジネスマンからお年寄りのご夫婦、家族連れなど幅広いお客様のニーズに寄り添った対応を心掛けてきました。 お年寄りのお荷物をお部屋まで運ぶ、お子様がいらしたときは小さな枕を探してお渡しするなど、マニュアルには載っていない、お客様のご要望に合ったサービスを自分からお声がけしておこないました。 お客様から「ありがとう」と言われる機会も増え、臨機応変な対応こそ、ホスピタリティで重要であることを肌で感じました。 御社に入社したあとは、この臨機応変に対応する力を生かし、お客様に寄り添った対応をしていきたいと考えています。output:臨機応変な対応//  input:私の強みは、計画性があり、優先順位をつけて効率的に取り組めることです。 大学では学内イベント企画の代表を勤め、企画してから実行までの半年間、メンバーの適正を考慮したうえで仕事を振り分け、計画的に準備を進めました。その結果、イベントも大盛況のうちに終えることができました。この成功体験を通じ、計画的に進めることの大切さを改めて感じています。 御社へ入社後も、業務を計画的に効率よく進め、大きな目標を達成していきたいと考えています。output:計画性,優先順位をつけて効率的に取り組める”  input:私は、物事の原因を分析し、適切な対応をすることで問題解決をすることができます。家庭教師のアルバイトをしていたのですが、担当した生徒は英語と歴史が苦手で点数が伸び悩んでいました。そこで、何が苦手であるかを徹底的に分析し、英語は文法が、歴史は時系列が曖昧であることがわかり、それに向けた対策方法として苦手を克服するパズルゲームのように教えるようにしました。その方法が合っていたのか、生徒はみるみる実力をつけ、今では英語と歴史は平均点以上をマークしています。御社へ入社後も、問題解決に向けた原因分析を徹底し、相手の会社が抱えている課題を解決できるよう提案できる営業を目指します。output:適切な対応をすることで問題解決をする”  input:私の強みはプレゼンテーション力があることです。アパレルショップでアルバイトをしていた際、お客様が迷っていたら、コーディネートのアドバイスなどをして売り上げを伸ばしていました。しかし、先輩から「売り上げに意識がいくあまり、アドバイスが的確でない」という指摘を受け、お客様のニーズをしっかり聞き出し、よりお客様のライフスタイルやトレンドに合った提案をするようにしました。その結果、特に売り上げを意識しなくても、自然に売り上げがついてきたのです。御社に入社後も、相手のニーズをしっかりと聞いたうえで適切な提案ができるよう努力したいと考えています。output:\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, is_decoder=True).to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = model.generate(\n",
    "        **inputs,\n",
    "        max_length=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )　\n",
    "\n",
    "output = tokenizer.decode(tokens[0], skip_special_tokens=True).replace(\" \", \"\")\n",
    "print(f\"{Fore.YELLOW}{prompt}{Fore.WHITE}{output[len(prompt):]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-testplay-oBgUYf3M-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
